{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet, Ridge\n",
    "from scipy.stats import zscore, mstats\n",
    "from constrained_linear_regression import ConstrainedLinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fed</th>\n",
       "      <th>GDP</th>\n",
       "      <th>VIX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>Fed_Hiking_60</td>\n",
       "      <td>GDP_Slowing_40</td>\n",
       "      <td>VIX_Low_40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 01:00:00</th>\n",
       "      <td>Fed_Hiking_60</td>\n",
       "      <td>GDP_Falling_40</td>\n",
       "      <td>VIX_Low_40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 02:00:00</th>\n",
       "      <td>Fed_Hiking_60</td>\n",
       "      <td>GDP_Accelerating_40</td>\n",
       "      <td>VIX_High_40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 03:00:00</th>\n",
       "      <td>Fed_Cutting_60</td>\n",
       "      <td>GDP_Slowing_40</td>\n",
       "      <td>VIX_High_40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:00:00</th>\n",
       "      <td>Fed_Cutting_60</td>\n",
       "      <td>GDP_Falling_40</td>\n",
       "      <td>VIX_Low_40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05 19:00:00</th>\n",
       "      <td>Fed_Hiking_60</td>\n",
       "      <td>GDP_Accelerating_40</td>\n",
       "      <td>VIX_High_40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05 20:00:00</th>\n",
       "      <td>Fed_Cutting_60</td>\n",
       "      <td>GDP_Accelerating_40</td>\n",
       "      <td>VIX_Medium_40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05 21:00:00</th>\n",
       "      <td>Fed_Cutting_60</td>\n",
       "      <td>GDP_Slowing_40</td>\n",
       "      <td>VIX_High_40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05 22:00:00</th>\n",
       "      <td>Fed_Hiking_60</td>\n",
       "      <td>GDP_Slowing_40</td>\n",
       "      <td>VIX_High_40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05 23:00:00</th>\n",
       "      <td>Fed_Cutting_60</td>\n",
       "      <td>GDP_Accelerating_40</td>\n",
       "      <td>VIX_Low_40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Fed                  GDP            VIX\n",
       "date                                                                   \n",
       "2018-01-01 00:00:00   Fed_Hiking_60       GDP_Slowing_40     VIX_Low_40\n",
       "2018-01-01 01:00:00   Fed_Hiking_60       GDP_Falling_40     VIX_Low_40\n",
       "2018-01-01 02:00:00   Fed_Hiking_60  GDP_Accelerating_40    VIX_High_40\n",
       "2018-01-01 03:00:00  Fed_Cutting_60       GDP_Slowing_40    VIX_High_40\n",
       "2018-01-01 04:00:00  Fed_Cutting_60       GDP_Falling_40     VIX_Low_40\n",
       "...                             ...                  ...            ...\n",
       "2018-01-05 19:00:00   Fed_Hiking_60  GDP_Accelerating_40    VIX_High_40\n",
       "2018-01-05 20:00:00  Fed_Cutting_60  GDP_Accelerating_40  VIX_Medium_40\n",
       "2018-01-05 21:00:00  Fed_Cutting_60       GDP_Slowing_40    VIX_High_40\n",
       "2018-01-05 22:00:00   Fed_Hiking_60       GDP_Slowing_40    VIX_High_40\n",
       "2018-01-05 23:00:00  Fed_Cutting_60  GDP_Accelerating_40     VIX_Low_40\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rolling_regression_sklearn_advanced(data, rolling_window, n_step_ahead=1, \n",
    "                                        l1_ratio=0.1, \n",
    "                                        dropna=False, remove_outliers=False, \n",
    "                                        winsorize=False, winsorize_limits=(0.05, 0.95),\n",
    "                                        fit_intercept=False, min_coef=None, max_coef=None):\n",
    "    \"\"\"\n",
    "    Perform rolling regression from sklearn with additional data processing options.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame where the last column is the target variable. \n",
    "                             Should have a DateTimeIndex.\n",
    "        rolling_window (int): Number of samples to use for each regression.\n",
    "        n_step_ahead (int, optional): Number of steps ahead to predict. Default is 1.\n",
    "        l1_ratio (float, optional): The L1 regularization ratio. Default is 0.1.\n",
    "        dropna (bool, optional): Whether to drop NaN values. Default is False.\n",
    "        remove_outliers (bool, optional): Whether to remove outliers based on Z-score. Default is False.\n",
    "        winsorize (bool, optional): Whether to winsorize data. Default is False.\n",
    "        winsorize_limits (tuple, optional): Percentiles for winsorizing. Default is (0.05, 0.95).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Coefficients for each window.\n",
    "        pd.Series: Predictions.\n",
    "    \"\"\"\n",
    "    # Drop NaN values if requested\n",
    "    if dropna:\n",
    "        data = data.dropna()\n",
    "    \n",
    "    n_samples, n_features_plus_one = data.shape\n",
    "    n_features = n_features_plus_one - 1\n",
    "    \n",
    "    coefs = pd.DataFrame(index=data.index, columns=[f'coef_{i}' for i in range(n_features)])\n",
    "    predictions = pd.Series(index=data.index, name='predictions')\n",
    "    \n",
    "    for start in range(0, n_samples - rolling_window - n_step_ahead + 1, n_step_ahead):\n",
    "        window = data.iloc[start:start + rolling_window].copy()  # Use copy to avoid SettingWithCopyWarning\n",
    "        \n",
    "        # Remove outliers if requested\n",
    "        if remove_outliers:\n",
    "            z_scores = np.abs(zscore(window))\n",
    "            window = window[(z_scores < 3).all(axis=1)]\n",
    "        \n",
    "        # Winsorize data if requested\n",
    "        if winsorize:\n",
    "            window = window.apply(lambda col: mstats.winsorize(col, limits=winsorize_limits), axis=0)\n",
    "        \n",
    "        # X, y = window.iloc[:, :-1], window.iloc[:, -1]\n",
    "        X, y = window.drop('target', axis=1), window['target']\n",
    "        # model = make_pipeline(StandardScaler(),\n",
    "        #                       Ridge(alpha = l1_ratio, fit_intercept=False),\n",
    "\n",
    "        #                      )\n",
    "        # scale_ = model.named_steps['standardscaler'].scale_\n",
    "        # coefs.iloc[end_idx] = model.named_steps['ridge'].coef_ / scale_\n",
    "\n",
    "\n",
    "        model = ConstrainedLinearRegression(ridge=l1_ratio, normalize=True, fit_intercept=fit_intercept)\n",
    "        model.fit(X, y, min_coef=min_coef, max_coef=max_coef)\n",
    "\n",
    "        end_idx = start + rolling_window\n",
    "\n",
    "        coefs.iloc[end_idx] = model.coef_\n",
    "        future_X = data.iloc[end_idx:end_idx + n_step_ahead, :-1]\n",
    "        future_preds = model.predict(future_X)\n",
    "        predictions.iloc[end_idx:end_idx + n_step_ahead] = future_preds\n",
    "        \n",
    "    return pd.concat([coefs, predictions], axis=1)\n",
    "\n",
    "\n",
    "# Assuming we have a DataFrame 'data' with the appropriate format, this function could be called as follows:\n",
    "# results = rolling_regression_sklearn_advanced(data, rolling_window=20)\n",
    "# But here, we will not run it as we don't have a predefined 'data' DataFrame.\n",
    "\n",
    "\n",
    "np.random.seed(20)\n",
    "data_df = pd.DataFrame()\n",
    "SIZE = 120\n",
    "data_df['data_1'] = np.random.normal(size=((SIZE)))\n",
    "data_df['data_2'] = np.random.normal(size=((SIZE)))\n",
    "data_df['target'] = data_df['data_1'] * 1.5 + data_df['data_2'] * 0.5 + np.random.normal(scale=0.2, size=((SIZE)))\n",
    "data_df['date'] = pd.date_range(start='1/1/2018', periods=len(data_df), freq='H')\n",
    "data_df = data_df.set_index('date')\n",
    "\n",
    "N_MACRO = 3\n",
    "MACRO_COLUMNS = ['Fed', 'GDP', 'VIX']\n",
    "df_regime = pd.DataFrame(np.random.normal(loc=0.1,size=(SIZE, N_MACRO)), index=data_df.index)\n",
    "df_regime.columns = MACRO_COLUMNS[:N_MACRO]\n",
    "df_regime\n",
    "def helper_regime(df_regime, q_list):\n",
    "    df_regimec = df_regime.copy()\n",
    "    for i, col in enumerate(df_regime):\n",
    "        q = q_list[i]\n",
    "        df_regimec[col] = np.ceil(df_regimec[col].rank(pct=True)*q)\n",
    "    return df_regimec\n",
    "\n",
    "label_dict = {'Fed': {1.0 : 'Hiking', 2.0: 'Cutting'},\n",
    "              'GDP': {1.0: 'Accelerating', 2.0: 'Slowing', 3.0: 'Falling'},\n",
    "              'VIX': {1.0: 'High', 2.0: 'Medium', 3.0: 'Low'},\n",
    "              }\n",
    "\n",
    "def get_df_regime_label(df_regime_discrete, label_dict):\n",
    "    df_regime_labelled = df_regime_discrete.copy()\n",
    "    for col, label_sub_dict in label_dict.items():\n",
    "        value_counts = df_regime_discrete[col].value_counts()\n",
    "        for value, label in label_sub_dict.items():\n",
    "            new_col = df_regime_labelled[col].replace(value, f'{col}_{label}_{value_counts[value]}')\n",
    "            df_regime_labelled[col] = new_col\n",
    "    return df_regime_labelled\n",
    "\n",
    "df_regime_discrete = helper_regime(df_regime, [2, 3, 3])        \n",
    "df_regime_labelled = get_df_regime_label(df_regime_discrete, label_dict)\n",
    "df_regime_labelled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wazir\\AppData\\Local\\Temp\\ipykernel_10896\\3924581582.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  pd.concat([df_regime_labelled, data_df], axis=1).groupby('Fed').mean()['data_1']\n",
      "C:\\Users\\Wazir\\AppData\\Local\\Temp\\ipykernel_10896\\3924581582.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  test = [pd.concat([df_regime_labelled, data_df], axis=1).groupby(col).mean()['data_1'] for col in MACRO_COLUMNS[:N_MACRO]]\n",
      "C:\\Users\\Wazir\\AppData\\Local\\Temp\\ipykernel_10896\\3924581582.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  test = [pd.concat([df_regime_labelled, data_df], axis=1).groupby(col).mean()['data_1'] for col in MACRO_COLUMNS[:N_MACRO]]\n",
      "C:\\Users\\Wazir\\AppData\\Local\\Temp\\ipykernel_10896\\3924581582.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  test = [pd.concat([df_regime_labelled, data_df], axis=1).groupby(col).mean()['data_1'] for col in MACRO_COLUMNS[:N_MACRO]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>data_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fed_Cutting_60</td>\n",
       "      <td>-0.003344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fed_Hiking_60</td>\n",
       "      <td>-0.094704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GDP_Accelerating_40</td>\n",
       "      <td>0.014295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GDP_Falling_40</td>\n",
       "      <td>0.072788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GDP_Slowing_40</td>\n",
       "      <td>-0.234155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VIX_High_40</td>\n",
       "      <td>-0.142273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VIX_Low_40</td>\n",
       "      <td>0.070370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VIX_Medium_40</td>\n",
       "      <td>-0.075168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 index    data_1\n",
       "0       Fed_Cutting_60 -0.003344\n",
       "1        Fed_Hiking_60 -0.094704\n",
       "2  GDP_Accelerating_40  0.014295\n",
       "3       GDP_Falling_40  0.072788\n",
       "4       GDP_Slowing_40 -0.234155\n",
       "5          VIX_High_40 -0.142273\n",
       "6           VIX_Low_40  0.070370\n",
       "7        VIX_Medium_40 -0.075168"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df_regime_labelled, data_df], axis=1).groupby('Fed').mean()['data_1']\n",
    "test = [pd.concat([df_regime_labelled, data_df], axis=1).groupby(col).mean()['data_1'] for col in MACRO_COLUMNS[:N_MACRO]]\n",
    "pd.DataFrame(pd.concat(test)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wazir\\AppData\\Local\\Temp\\ipykernel_10896\\1021464922.py:32: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  predictions = pd.Series(index=data.index, name='predictions')\n",
      "c:\\Users\\Wazir\\anaconda3\\envs\\regtool\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but ConstrainedLinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Wazir\\anaconda3\\envs\\regtool\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but ConstrainedLinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Wazir\\anaconda3\\envs\\regtool\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but ConstrainedLinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Wazir\\anaconda3\\envs\\regtool\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but ConstrainedLinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Wazir\\anaconda3\\envs\\regtool\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but ConstrainedLinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Wazir\\anaconda3\\envs\\regtool\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but ConstrainedLinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Wazir\\anaconda3\\envs\\regtool\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but ConstrainedLinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Wazir\\anaconda3\\envs\\regtool\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but ConstrainedLinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Wazir\\anaconda3\\envs\\regtool\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but ConstrainedLinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Wazir\\anaconda3\\envs\\regtool\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but ConstrainedLinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Wazir\\anaconda3\\envs\\regtool\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but ConstrainedLinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Wazir\\anaconda3\\envs\\regtool\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but ConstrainedLinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Wazir\\anaconda3\\envs\\regtool\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but ConstrainedLinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Wazir\\anaconda3\\envs\\regtool\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but ConstrainedLinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Wazir\\anaconda3\\envs\\regtool\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but ConstrainedLinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Wazir\\anaconda3\\envs\\regtool\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but ConstrainedLinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Wazir\\anaconda3\\envs\\regtool\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but ConstrainedLinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Wazir\\anaconda3\\envs\\regtool\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but ConstrainedLinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Wazir\\anaconda3\\envs\\regtool\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but ConstrainedLinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Wazir\\anaconda3\\envs\\regtool\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but ConstrainedLinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.199859619140625"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the function and measuring execution time\n",
    "rolling_window = 100\n",
    "n_step_ahead = 1\n",
    "start_time_advanced = time.time()\n",
    "df_results = rolling_regression_sklearn_advanced(\n",
    "    data_df, rolling_window=rolling_window, n_step_ahead=n_step_ahead,\n",
    "    dropna=False, remove_outliers=False, winsorize=False, winsorize_limits=(0.01, 0.99)\n",
    ")\n",
    "end_time_advanced = time.time()\n",
    "time_advanced = end_time_advanced - start_time_advanced\n",
    "time_advanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef_0</th>\n",
       "      <th>coef_1</th>\n",
       "      <th>predictions</th>\n",
       "      <th>data_1</th>\n",
       "      <th>data_2</th>\n",
       "      <th>target</th>\n",
       "      <th>shap_1</th>\n",
       "      <th>shap_2</th>\n",
       "      <th>pred_shap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.883893</td>\n",
       "      <td>0.289559</td>\n",
       "      <td>1.315804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 01:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.195865</td>\n",
       "      <td>-0.470209</td>\n",
       "      <td>-0.155492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 02:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.357537</td>\n",
       "      <td>1.605993</td>\n",
       "      <td>1.213914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 03:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.343262</td>\n",
       "      <td>-0.153662</td>\n",
       "      <td>-3.807196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.084833</td>\n",
       "      <td>-1.786169</td>\n",
       "      <td>-2.264937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05 19:00:00</th>\n",
       "      <td>1.505092</td>\n",
       "      <td>0.485731</td>\n",
       "      <td>-1.576530</td>\n",
       "      <td>-1.334921</td>\n",
       "      <td>0.890717</td>\n",
       "      <td>-1.768914</td>\n",
       "      <td>-2.009179</td>\n",
       "      <td>0.432649</td>\n",
       "      <td>-1.576530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05 20:00:00</th>\n",
       "      <td>1.507695</td>\n",
       "      <td>0.484474</td>\n",
       "      <td>1.134139</td>\n",
       "      <td>0.676640</td>\n",
       "      <td>0.235252</td>\n",
       "      <td>1.398751</td>\n",
       "      <td>1.020166</td>\n",
       "      <td>0.113973</td>\n",
       "      <td>1.134139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05 21:00:00</th>\n",
       "      <td>1.509077</td>\n",
       "      <td>0.486443</td>\n",
       "      <td>1.209178</td>\n",
       "      <td>0.831106</td>\n",
       "      <td>-0.092560</td>\n",
       "      <td>0.996478</td>\n",
       "      <td>1.254203</td>\n",
       "      <td>-0.045025</td>\n",
       "      <td>1.209178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05 22:00:00</th>\n",
       "      <td>1.509243</td>\n",
       "      <td>0.489146</td>\n",
       "      <td>-0.800945</td>\n",
       "      <td>-0.365057</td>\n",
       "      <td>-0.511063</td>\n",
       "      <td>-0.732631</td>\n",
       "      <td>-0.55096</td>\n",
       "      <td>-0.249985</td>\n",
       "      <td>-0.800945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05 23:00:00</th>\n",
       "      <td>1.507894</td>\n",
       "      <td>0.488274</td>\n",
       "      <td>1.039025</td>\n",
       "      <td>0.496770</td>\n",
       "      <td>0.593823</td>\n",
       "      <td>0.861704</td>\n",
       "      <td>0.749077</td>\n",
       "      <td>0.289948</td>\n",
       "      <td>1.039025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       coef_0    coef_1  predictions    data_1    data_2  \\\n",
       "date                                                                       \n",
       "2018-01-01 00:00:00       NaN       NaN          NaN  0.883893  0.289559   \n",
       "2018-01-01 01:00:00       NaN       NaN          NaN  0.195865 -0.470209   \n",
       "2018-01-01 02:00:00       NaN       NaN          NaN  0.357537  1.605993   \n",
       "2018-01-01 03:00:00       NaN       NaN          NaN -2.343262 -0.153662   \n",
       "2018-01-01 04:00:00       NaN       NaN          NaN -1.084833 -1.786169   \n",
       "...                       ...       ...          ...       ...       ...   \n",
       "2018-01-05 19:00:00  1.505092  0.485731    -1.576530 -1.334921  0.890717   \n",
       "2018-01-05 20:00:00  1.507695  0.484474     1.134139  0.676640  0.235252   \n",
       "2018-01-05 21:00:00  1.509077  0.486443     1.209178  0.831106 -0.092560   \n",
       "2018-01-05 22:00:00  1.509243  0.489146    -0.800945 -0.365057 -0.511063   \n",
       "2018-01-05 23:00:00  1.507894  0.488274     1.039025  0.496770  0.593823   \n",
       "\n",
       "                       target    shap_1    shap_2  pred_shap  \n",
       "date                                                          \n",
       "2018-01-01 00:00:00  1.315804       NaN       NaN   0.000000  \n",
       "2018-01-01 01:00:00 -0.155492       NaN       NaN   0.000000  \n",
       "2018-01-01 02:00:00  1.213914       NaN       NaN   0.000000  \n",
       "2018-01-01 03:00:00 -3.807196       NaN       NaN   0.000000  \n",
       "2018-01-01 04:00:00 -2.264937       NaN       NaN   0.000000  \n",
       "...                       ...       ...       ...        ...  \n",
       "2018-01-05 19:00:00 -1.768914 -2.009179  0.432649  -1.576530  \n",
       "2018-01-05 20:00:00  1.398751  1.020166  0.113973   1.134139  \n",
       "2018-01-05 21:00:00  0.996478  1.254203 -0.045025   1.209178  \n",
       "2018-01-05 22:00:00 -0.732631  -0.55096 -0.249985  -0.800945  \n",
       "2018-01-05 23:00:00  0.861704  0.749077  0.289948   1.039025  \n",
       "\n",
       "[120 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shap = pd.concat([df_results, data_df], axis=1)\n",
    "df_shap['shap_1'] = df_shap['coef_0'] * df_shap['data_1']\n",
    "df_shap['shap_2'] = df_shap['coef_1'] * df_shap['data_2']\n",
    "df_shap['pred_shap'] = df_shap.filter(regex='shap').sum(axis=1)\n",
    "df_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap = np.array([1.0, -0.5])\n",
    "pred = shap.sum()\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 0.5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2_m</th>\n",
       "      <th>X1_lag1</th>\n",
       "      <th>X2_m_lag1</th>\n",
       "      <th>X2_m_lag2</th>\n",
       "      <th>X2_m_diff_1d_lag1</th>\n",
       "      <th>X2_m_pct_change_1d_lag1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2_m  X1_lag1  X2_m_lag1  X2_m_lag2  X2_m_diff_1d_lag1  \\\n",
       "0   0     1      NaN        NaN        NaN                NaN   \n",
       "1   1     1      0.0        NaN        NaN                NaN   \n",
       "2   2     1      1.0        NaN        NaN                NaN   \n",
       "3   3     2      2.0        1.0        NaN                NaN   \n",
       "4   4     2      3.0        1.0        NaN                1.0   \n",
       "5   5     2      4.0        1.0        NaN                1.0   \n",
       "6   6     3      5.0        2.0        1.0                1.0   \n",
       "7   7     3      6.0        2.0        1.0                1.0   \n",
       "8   8     4      7.0        3.0        2.0                1.0   \n",
       "9   9     4      8.0        3.0        2.0                1.0   \n",
       "\n",
       "   X2_m_pct_change_1d_lag1  \n",
       "0                      NaN  \n",
       "1                      NaN  \n",
       "2                      NaN  \n",
       "3                      NaN  \n",
       "4                 1.000000  \n",
       "5                 1.000000  \n",
       "6                 1.000000  \n",
       "7                 0.500000  \n",
       "8                 0.500000  \n",
       "9                 0.333333  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_engineering(df, transformations):\n",
    "    '''\n",
    "    Extends the dataframe with engineered features based on the specified transformations.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original dataframe.\n",
    "        transformations (dict): A dictionary with keys as column names and values as lists of transformations.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe with added engineered features.\n",
    "    '''\n",
    "    engineered_df = df.copy()\n",
    "    \n",
    "    for column, transformation_list in transformations.items():\n",
    "        monthly = True if column[-2:] == '_m' else False\n",
    "        for transformation in transformation_list:\n",
    "            operation, *params = transformation  # Unpack operation and parameters\n",
    "            \n",
    "            if operation in ['mean', 'std', 'kurt', 'pct_change', 'diff']:\n",
    "                window = params[0]\n",
    "                lag = params[1] if len(params) > 1 else 0  # Use lag if provided, else default to 0\n",
    "                if monthly:\n",
    "                    monthly_series = df[column][df[column].diff() != 0].copy()\n",
    "                    if operation in ['mean', 'std', 'kurt']:\n",
    "                        rolled_series = getattr(monthly_series.rolling(window=window), operation)()\n",
    "                    elif operation == 'pct_change':\n",
    "                        rolled_series = monthly_series.pct_change(periods=window).reindex(df.index)\n",
    "                    elif operation == 'diff':\n",
    "                        rolled_series = monthly_series.diff(periods=window).reindex(df.index)\n",
    "                    engineered_df[f\"{column}_{operation}_{window}d_lag{lag}\"] = rolled_series.shift(lag).reindex(df.index).ffill()\n",
    "                else:\n",
    "                    if operation in ['mean', 'std', 'kurt']:\n",
    "                        rolled_series = getattr(df[column].rolling(window=window), operation)()\n",
    "                    elif operation == 'pct_change':\n",
    "                        rolled_series = df[column].pct_change(periods=window)\n",
    "                    elif operation == 'diff':\n",
    "                        rolled_series = df[column].diff(periods=window)\n",
    "                    engineered_df[f\"{column}_{operation}_{window}d_lag{lag}\"] = rolled_series.shift(lag)\n",
    "\n",
    "            elif operation == 'lag':\n",
    "                lag = params[0]\n",
    "                if monthly:\n",
    "                    monthly_series = df[column][df[column].diff() != 0].copy()\n",
    "                    engineered_df[f\"{column}_lag{lag}\"] = monthly_series.shift(lag).reindex(df.index).ffill()\n",
    "                else:\n",
    "                    engineered_df[f\"{column}_lag{lag}\"] = df[column].shift(lag)\n",
    "\n",
    "    return engineered_df\n",
    "\n",
    "\n",
    "# def fea\n",
    "\n",
    "example_df = pd.DataFrame({\"X1\": range(10),\n",
    "                           'X2_m': [1, 1, 1, 2, 2, 2, 3, 3, 4, 4]})\n",
    "transformations_new = { 'X1': [['lag', 1]],\n",
    "                        'X2_m': [['lag', 1], ['lag', 2], ['diff', 1, 1], ['pct_change', 1, 1]]\n",
    "                        }\n",
    "\n",
    "df = feature_engineering(example_df, transformations_new)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2_m</th>\n",
       "      <th>X1_mean_1d_</th>\n",
       "      <th>X2_m_diff_1d_</th>\n",
       "      <th>X2_m_pct_change_1d_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2_m  X1_mean_1d_  X2_m_diff_1d_  X2_m_pct_change_1d_\n",
       "0   0     1          0.0            NaN                  NaN\n",
       "1   1     1          1.0            0.0             0.000000\n",
       "2   2     1          2.0            0.0             0.000000\n",
       "3   3     2          3.0            1.0             1.000000\n",
       "4   4     2          4.0            0.0             0.000000\n",
       "5   5     2          5.0            0.0             0.000000\n",
       "6   6     3          6.0            1.0             0.500000\n",
       "7   7     3          7.0            0.0             0.000000\n",
       "8   8     4          8.0            1.0             0.333333\n",
       "9   9     4          9.0            0.0             0.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_engineering_updated(df, transformations):\n",
    "    '''\n",
    "    Extends the dataframe with engineered features based on the specified transformations.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original dataframe.\n",
    "        transformations (dict): A dictionary with keys as column names and values as lists of transformations.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe with added engineered features.\n",
    "    '''\n",
    "    engineered_df = df.copy()\n",
    "    \n",
    "    for column, transformation_list in transformations.items():\n",
    "        for transformation in transformation_list:\n",
    "            operation, window = transformation  # Unpack operation and parameters\n",
    "            if operation in ['mean', 'std', 'kurt', 'pct_change', 'diff']:\n",
    "                if operation in ['mean', 'std', 'kurt']:\n",
    "                    transformed_series = getattr(df[column].rolling(window=window), operation)()\n",
    "                elif operation == 'pct_change':\n",
    "                    transformed_series = df[column].pct_change(periods=window)\n",
    "                elif operation == 'diff':\n",
    "                    transformed_series = df[column].diff(periods=window)\n",
    "                engineered_df[f\"{column}_{operation}_{window}d\"] = transformed_series\n",
    "    return engineered_df\n",
    "\n",
    "\n",
    "example_df = pd.DataFrame({\"X1\": range(10),\n",
    "                           'X2_m': [1, 1, 1, 2, 2, 2, 3, 3, 4, 4]})\n",
    "transformations_new = { 'X1': [['mean', 1]],\n",
    "                        'X2_m': [['diff', 1], ['pct_change', 1]]\n",
    "                        }\n",
    "\n",
    "feature_engineering_updated(example_df, transformations_new)\n",
    "\n",
    "\n",
    "def lag_variables(df, lag_dict):\n",
    "    dfc = df.copy()\n",
    "    for col, windows in lag_dict.items():\n",
    "        for window in windows:\n",
    "            dfc[f'{col}_lag{window}'] = dfc[col].shift(window)\n",
    "\n",
    "    return dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_monthly = pd.read_excel('../Data/sample_data.xlsx', skiprows=1)\n",
    "df_monthly.columns = ['Date', 'CPI-U_SA', 'CPI-U_NSA', 'Manheim_Used_Vehicle', 'PPI_Used_Vehicles', 'PPI_Automotive', 'PPI_Passenger_Cars', '5y_Treasury']\n",
    "df_monthly['Date'] = pd.to_datetime(df_monthly['Date'])\n",
    "df_monthly.set_index('Date', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPI-U_SA</th>\n",
       "      <th>CPI-U_SA</th>\n",
       "      <th>Manheim_Used_Vehicle</th>\n",
       "      <th>PPI_Used_Vehicles</th>\n",
       "      <th>PPI_Automotive</th>\n",
       "      <th>PPI_Passenger_Cars</th>\n",
       "      <th>5y_Treasury</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-31</th>\n",
       "      <td>153.900</td>\n",
       "      <td>153.900</td>\n",
       "      <td>109.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.400</td>\n",
       "      <td>6.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-29</th>\n",
       "      <td>153.000</td>\n",
       "      <td>152.998</td>\n",
       "      <td>109.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.700</td>\n",
       "      <td>6.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-31</th>\n",
       "      <td>153.000</td>\n",
       "      <td>152.975</td>\n",
       "      <td>110.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.700</td>\n",
       "      <td>6.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-30</th>\n",
       "      <td>154.000</td>\n",
       "      <td>153.975</td>\n",
       "      <td>109.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.800</td>\n",
       "      <td>6.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-31</th>\n",
       "      <td>155.400</td>\n",
       "      <td>155.385</td>\n",
       "      <td>110.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.500</td>\n",
       "      <td>6.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-30</th>\n",
       "      <td>198.746</td>\n",
       "      <td>202.007</td>\n",
       "      <td>215.1</td>\n",
       "      <td>113.417</td>\n",
       "      <td>241.519</td>\n",
       "      <td>139.972</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-31</th>\n",
       "      <td>196.086</td>\n",
       "      <td>201.624</td>\n",
       "      <td>211.7</td>\n",
       "      <td>105.340</td>\n",
       "      <td>241.128</td>\n",
       "      <td>140.277</td>\n",
       "      <td>4.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-31</th>\n",
       "      <td>193.671</td>\n",
       "      <td>198.768</td>\n",
       "      <td>212.2</td>\n",
       "      <td>107.378</td>\n",
       "      <td>242.503</td>\n",
       "      <td>140.669</td>\n",
       "      <td>4.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30</th>\n",
       "      <td>188.772</td>\n",
       "      <td>187.587</td>\n",
       "      <td>214.3</td>\n",
       "      <td>107.378</td>\n",
       "      <td>245.368</td>\n",
       "      <td>140.831</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            CPI-U_SA  CPI-U_SA  Manheim_Used_Vehicle  PPI_Used_Vehicles  \\\n",
       "Date                                                                      \n",
       "2000-01-31   153.900   153.900                 109.1                NaN   \n",
       "2000-02-29   153.000   152.998                 109.5                NaN   \n",
       "2000-03-31   153.000   152.975                 110.1                NaN   \n",
       "2000-04-30   154.000   153.975                 109.8                NaN   \n",
       "2000-05-31   155.400   155.385                 110.2                NaN   \n",
       "...              ...       ...                   ...                ...   \n",
       "2023-06-30   198.746   202.007                 215.1            113.417   \n",
       "2023-07-31   196.086   201.624                 211.7            105.340   \n",
       "2023-08-31   193.671   198.768                 212.2            107.378   \n",
       "2023-09-30   188.772   187.587                 214.3            107.378   \n",
       "2023-10-31       NaN       NaN                 209.4                NaN   \n",
       "\n",
       "            PPI_Automotive  PPI_Passenger_Cars  5y_Treasury  \n",
       "Date                                                         \n",
       "2000-01-31             NaN             133.400         6.58  \n",
       "2000-02-29             NaN             132.700         6.68  \n",
       "2000-03-31             NaN             132.700         6.50  \n",
       "2000-04-30             NaN             132.800         6.26  \n",
       "2000-05-31             NaN             133.500         6.69  \n",
       "...                    ...                 ...          ...  \n",
       "2023-06-30         241.519             139.972         3.95  \n",
       "2023-07-31         241.128             140.277         4.14  \n",
       "2023-08-31         242.503             140.669         4.31  \n",
       "2023-09-30         245.368             140.831         4.49  \n",
       "2023-10-31             NaN                 NaN         4.77  \n",
       "\n",
       "[286 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_monthly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantmacro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
